---
title: "Normalisation of CAGE data by sub-sampling"
author:
 - "Charles Plessy"
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---
```{r echo=FALSE}
knitr::opts_chunk$set(cache=FALSE)
options(width=150)
```

The number of different genes detected when sequencing a transcriptome library
increases slower and slower as reads are added: by definition the first read is
always new; the second has high chances to be different from the first, etc.,
but after millions of them each extra read will have much higer chances to be
identical to another read already sequenced.  The consequence of this is that
analysing the same library sequenced _deeply_, for instance on HiSeq, or
_shallowly_, for instance on MiSeq, will not yield the same result in terms of
gene discovery, etc.  See [Dave Tang's blog][Dave] for a longer discussion on
sequencing depth.

[Dave]: http://davetang.org/muse/2013/07/10/how-deep-should-we-sequence/ "How deep should we sequence ?"

This tutorial is about comparing libraries on properties that are not invariant
with sequencing depth.  The solution presented here is to normalise the
libraries to the same _depth_, that is, to use the same number of reads for
each library.  There are mainly two ways: either input a fixed number of reads
in the alignment pipeline, or sub-sample a fixed number of alignments after
using all the reads.  This tutorial shows how do the second solution for CAGE
data using `R`.

Busy people familiar with CAGE and R can skip the tutorial and read the manual
of the `rrarefy` command of the [vegan][] package.

[vegan]: http://vegan.r-forge.r-project.org/

## Information and download

See the main [README](../README.md) for general recommendations on how or what
to prepare before running this tutorial.

The data downloaded here is the count of CAGE tags in the FANTOM5 CAGE peaks
for all the _Phase 1_ libraries of the [FANTOM 5 project][F5].  See the
[README][F5 README] file for more information on that file

[F5]: http://fantom.gsc.riken.jp
[F5 README]: http://fantom.gsc.riken.jp/5/datafiles/latest/extra/CAGE_peaks/00_readme.txt

```{r download_material, engine="bash"}
wget --quiet --timestamping https://fantom.gsc.riken.jp/5/datafiles/latest/extra/CAGE_peaks/hg19.cage_peak_phase1and2combined_counts.osc.txt.gz
echo "0b288555ef51d1f1f9f04a2536d51a1d  hg19.cage_peak_phase1and2combined_counts.osc.txt.gz" | md5sum -c
```

## Data loading and preparation in R

The table is in [Order-Switchable Columns][OSC] format.  The [read.table][]
command in R will automatically discard its comment lines, set up column names
with the `header=TRUE` option and row names with the `row.names=1` option.

[read.table]: http://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html
[OSC]: http://sourceforge.net/projects/osctf/

The table is large: so loading the table will take time…

```{r load_data, dependson="download_material"}
osc <- read.table('hg19.cage_peak_phase1and2combined_counts.osc.txt.gz', row.names=1, header=TRUE)
dim(osc)
```

The name of the libraries are long because they contain a plain English
description of their contents.  We will shorten them to their identifier.  For
example, `counts.Adipocyte%20-%20breast%2c%20donor1.CNhs11051.11376-118A8`
becomes `CNhs11051`.  The association can be re-made using [FANTOM5 SDRF
files](../FANTOM5_SDRF_files/sdrf.md).

```{r column_names, dependson="load_data"}
colnames(osc) <- regmatches(colnames(osc), regexpr('CNhs.....', colnames(osc)))
```

The first line, `01STAT:MAPPED`, is special and contains the total number of
tags for each library.  The sum of all tags in all peaks is lower than this,
because some tags are not in peaks.  We will change the value of
`01STAT:MAPPED` so that the sum of the columns in our table is the total number
of reads for each library.

```{r stat_mapped, dependson="column_names"}
summary(t(osc["01STAT:MAPPED",]))
osc['01STAT:MAPPED',] <- osc['01STAT:MAPPED',] - colSums(osc[-grep('01STAT:MAPPED', rownames(osc)),])
summary(colSums(osc), digits=10)
```

## Number of peaks detected and total number of tags, part 1

Let's see now how many CAGE peaks are detected per library.  The command `osc >
0` produces a data frame containing `TRUE` where a tag count was higher than
zero, and `FALSE` otherwise.  In `R`, since `TRUE` equals 1 and `FALSE` equals
0, the `colSums` command applied on this data fame of TRUE/FALSE values will
then count the detected peaks.  (Note: the proper name of TRUE/FALSE values is
_boolean_.)

```{r peak_count1a, dependson="stat_mapped"}
summary(colSums(osc > 0), digits=10)
```

There are large variations in the number of peaks detected.  Let's take the example
of subcutaneous adipocytes (libraries [CNhs12494][], [CNhs11371][] and [CNhs12017][]).

[CNhs12494]: http://fantom.gsc.riken.jp/5/sstar/FF:11259-116F8 "Adipocyte - subcutaneous, donor1"
[CNhs11371]: http://fantom.gsc.riken.jp/5/sstar/FF:11336-117F4 "Adipocyte - subcutaneous, donor2"
[CNhs12017]: http://fantom.gsc.riken.jp/5/sstar/FF:11408-118E4 "Adipocyte - subcutaneous, donor3"

```{r peak_count1b, dependson="stat_mapped"}
numberOfPeaks <- colSums(osc > 0)
numberOfTags <- colSums(osc)
adipocytes <- c('CNhs12494', 'CNhs11371', 'CNhs12017')
numberOfPeaks[adipocytes]
numberOfTags[adipocytes]
```

Do we see more peaks just because there were more tags ?

## Sub-sampling

Here, we will remove tags from the data until each library has the same number of tags,
that is, we will normalise the _sequencing depth_ on the most _shallow_ library.

We will use the `rrarefy` command of the [vegan] package.  Unlike most R
commands that work on data frames, this command uses rows by default, so we
will transpose the table, sub-sample it, and transpose it again.

The sub-sampling removes tags randomly, so each time it is run it will never
produce exactly the same result.  However, highly expressed peaks will stay
highly expressed, etc.  For this tutorial, the computation is made identical
across runs by setting the random number seed with the `set.seed` command (and
resetting it with `rm(.Random.seed)`).  _Note: do not use `set.seed()` in your
project if you do not understand well the consequences._

```{r rrarefy, dependson="stat_mapped"}
library(vegan)
set.seed(1)
minNumberOfTags <- 500000
# Let's discard the libraries that do not have enough tags.
summary(numberOfTags > minNumberOfTags)
osc.sub <- t(rrarefy(t(osc[,numberOfTags > minNumberOfTags]), minNumberOfTags))
rm(.Random.seed)
summary(colSums(osc.sub), digits=10)
```

That is all !  Now all the libraries contain the same number of tags.

## Number of peaks detected and total number of tags, part 2

```{r peakNumberBarplot, dependson="stat_mapped", dev="svg"}
normalisedNumberOfPeaks <- colSums(osc.sub > 0)
normalisedNumberOfPeaks[adipocytes]
colSums(osc.sub)[adipocytes]
barplot( log10( cbind( normalisedNumberOfPeaks[adipocytes]
                     , numberOfPeaks[adipocytes]
                     , numberOfTags[adipocytes])
              )
       , beside=TRUE
       , legend=TRUE
       , args.legend=list( x="topleft"
                         , title="library ID")
       , main="Effect of sub-sampling normalisation on number of detected peaks"
       , ylab="log10"
)
```

The number of detected peaks is now very similar between the three biological replicates !

## Further uses of sub-sampling.

One can also use sub-sampling to compare the expression profile of CAGE peaks,
normalising for the fact that low-expressed peaks will be found in less
libraries.  The solution would be asking a question like _“what would be the
profile of a promoter if only 100 reads had aligned to it ?”_.  This question
is related to the supplementary note number 4 of the FANTOM 5 paper ([Forrest
_et al._, 2014][F5-paper]), on ubiquitous and tissue-restricted expression, and
will be the topic of a future tutorial.

[F5-paper]: http://dx.doi.org/10.1038/nature13182 "Forrest et al., 2014"

## Session information

```{r}
sessionInfo()
```